# https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties.integration.spring.kafka.admin.auto-create
spring:
  kafka:
    #設定kafka的broker位址
    bootstrap-servers: "127.0.0.1:9092"

    consumer:
      bootstrap-servers: "127.0.0.1:9092"
      group-id: test
      # 當Kafka中沒有初始偏移量或伺服器上不再存在當前偏移量時該怎麼辦
      # earliest：自動將偏移量重設為最早的偏移量
      # latest：自動將偏移量重設為最遲的偏移量
      # none：如果未找到消費者群組的先前偏移量，則將例外狀況拋出給消費者
      # exception：向消費者拋出異常
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # Whether the consumer's offset is periodically committed in the background.
      #enable-auto-commit:
      # Frequency with which the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' is set to true.
      #auto-commit-interval:
      # Maximum number of records returned in a single call to poll().default: 500
      #max-poll-records:
      # Maximum amount of time the server blocks before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by "fetch-min-size".
      #fetch-max-wait:
      # Minimum amount of data the server should return for a fetch request.
      #fetch-min-size:
      # Expected time between heartbeats to the consumer coordinator.
      #heartbeat-interval:

    producer:
      bootstrap-servers: "127.0.0.1:9092"
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # Number of acknowledgments the producer requires the leader to have received before considering a request complete.
      #“0”：表示生產者資料傳送到leader就算寫入成功
      #“1"：表示生產者資料傳送到leader並寫入到磁碟才算寫入成功
      #“-1”， “all“：表示生產者把資料送到leader，並同步到其他副本，才算資料寫入成功
      #acks:
      # Default batch size. A small batch size will make batching less common and may reduce throughput (a batch size of zero disables batching entirely).
      #batch-size:
      # Total memory size the producer can use to buffer records waiting to be sent to the server.
      #buffer-memory:
      # When greater than zero, enables retrying of failed sends.
      #retries:
      # When non empty, enables transaction support for producer.
      #transaction-id-prefix:
      # Compression type for all data generated by the producer.
      #compression-type:

    listener:
      type: single
      #當 auto.commit.enable 設定為false時，表示kafak的offset由customer手動維護，spring-kafka提供了透過ackMode的值表示不同的手動提交方式；
      #AckMode.RECORD 當每一筆記錄被消費者監聽器（ListenerConsumer）處理之後提交
      #AckMode.BATCH 當每一批poll()的資料被消費者監聽器（ListenerConsumer）處理之後提交
      #AckMode.TIME 當每一批poll()的資料被消費者監聽器（ListenerConsumer）處理之後，距離上次提交時間大於TIME時提交
      #AckMode.COUNT 當每一批poll()的資料被消費者監聽器（ListenerConsumer）處理之後，被處理record數量大於等於COUNT時提交
      #AckMode.COUNT_TIME 上述 TIM 或 COUNT 有一個條件滿足時提交
      #AckMode.MANUAL 當每一批poll()的資料被消費者監聽器（ListenerConsumer）處理之後, 手動呼叫Acknowledgment.acknowledge()後提交
      #AckMode.MANUAL_IMMEDIATE 手動呼叫Acknowledgment.acknowledge()後立即提交
      #ack-mode:
